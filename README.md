# Автоматична кластеризація зображень

Інструмент для автоматичного групування великого набору зображень у чисті кластери за структурною схожістю. Пайплайн будується на витягуванні ознак нейромережею, зменшенні розмірності та density-based кластеризації, а також містить модуль валідації чистоти кластерів (purity) і масовий ітеративний тюнінг.

## Зміст

- [Встановлення](#встановлення)
- [Запуск](#запуск)
- [Як працює](#як-працює)
  - [Пайплайн](#пайплайн)
  - [Алгоритмічна логіка](#алгоритмічна-логіка)
- [Структура проєкту](#структура-проєкту)
- [Конфігурація](#конфігурація)
  - [Вхід / Вихід](#вхід--вихід)
  - [Модель](#модель)
  - [Препроцесинг](#препроцесинг)
  - [Зменшення розмірності](#зменшення-розмірності)
  - [Кластеризація](#кластеризація)
  - [Візуалізація](#візуалізація)
  - [Анотації (YOLO)](#анотації-yolo)
  - [Кешування](#кешування)
  - [Прискорення (CPU/CUDA)](#прискорення-cpucuda)
- [Візуалізації](#візуалізації)
- [Ітеративний тюнінг](#ітеративний-тюнінг-iterative_tuningpy)
  - [Навігація по розділу](#навігація-по-розділу)
  - [Для чого потрібен](#для-чого-потрібен)
  - [Життєвий цикл запуску](#життєвий-цикл-запуску)
  - [Алгоритм пошуку (grid / evolution)](#алгоритм-пошуку-grid--evolution)
  - [Двофазний режим](#двофазний-режим)
  - [Early stop (плато)](#early-stop-плато)
  - [Як інтерпретувати метрики](#як-інтерпретувати-метрики)
  - [Артефакти та звітність](#артефакти-та-звітність)
- [Поради з налаштування](#поради-з-налаштування)

## Встановлення

Потрібен Python 3.10+ та NVIDIA GPU (рекомендовано, але не обов'язково).

```bash
# Створення віртуального середовища
python -m venv venv
venv\Scripts\activate        # Windows
# source venv/bin/activate   # Linux/macOS

# Встановлення залежностей
pip install -r requirements.txt
```

### Залежності

| Пакет | Призначення |
|---|---|
| `torch`, `torchvision` | Нейронна мережа (inference) |
| `Pillow` | Завантаження зображень |
| `opencv-python` | CLAHE, конвертація кольорів |
| `scikit-learn` | PCA, NearestCentroid |
| `umap-learn` | UMAP (зменшення розмірності) |
| `hdbscan` | Density-based кластеризація |
| `numpy` | Матричні операції |
| `pyyaml` | Парсинг конфігурації |
| `tqdm` | Прогрес-бари |
| `matplotlib` | Статичні візуалізації (графіки, сітки) |

PyTorch встановлюється через `requirements.txt`. Для GPU-прискорення переконайтесь, що встановлена версія з підтримкою CUDA (див. [pytorch.org](https://pytorch.org/get-started/locally/)).

## Запуск

```bash
# З конфігурацією за замовчуванням (config.yaml в поточній директорії)
python main.py

# З іншим файлом конфігурації
python main.py --config path/to/my_config.yaml
```

Програма виконує 7 кроків послідовно:

1. Завантаження конфігурації
2. Рекурсивне сканування зображень
3. Витягування ознак нейронною мережею (або з кешу)
4. Зменшення розмірності (PCA + UMAP)
5. Кластеризація (HDBSCAN)
6. Генерація візуалізацій
7. Підтвердження від користувача і розкладання файлів по папках

Перед переміщенням/копіюванням файлів програма виводить таблицю з кількістю знайдених кластерів та зображень у кожному, і чекає підтвердження (`y`/`n`).

## Як працює

### Пайплайн

```
Зображення (папка)
      │
      ▼
┌─────────────────┐
│ Препроцесинг    │  Grayscale → [Invert] → Equalization → RGB
│                 │  (два варіанти при polarity_invariant)
└────────┬────────┘
         ▼
┌─────────────────┐
│ Нейронна мережа │  DINOv2 ViT-B/14 → 768-dim вектор ознак
│                 │  (усереднення normal + inverted при dual-pass)
└────────┬────────┘
         ▼
┌─────────────────┐
│ L2-нормалізація │  Прибирає вплив магнітуди → unit vector
└────────┬────────┘
         ▼
┌─────────────────┐
│ PCA             │  768 → 100 dim (лінійне зменшення, шумозаглушення)
└────────┬────────┘
         ▼
┌─────────────────┐
│ UMAP            │  100 → 5 dim (нелінійне, зберігає структуру)
└────────┬────────┘
         ▼
┌─────────────────┐
│ HDBSCAN         │  Density-based кластеризація → мітки кластерів
└────────┬────────┘
         ▼
┌─────────────────┐
│ Організація     │  Копіювання/переміщення по папках cluster_NNN/
│ файлів          │  + перенос YOLO-анотацій (img/ + lab/)
└─────────────────┘
```

### Алгоритмічна логіка

Пайплайн побудований так, щоб розділити задачу на незалежні обчислювальні шари:

1. **Формування ознак**: модель переводить зображення у вектор уніфікованої розмірності.
2. **Стиснення простору**: PCA прибирає шум і надлишкові компоненти.
3. **Нелінійне вкладення**: UMAP формує представлення, зручне для пошуку щільностей.
4. **Кластеризація щільності**: HDBSCAN визначає кластери та шум без фіксованого `k`.
5. **Валідація якості**: purity-метрики оцінюють ізоляцію між кластерами.
6. **Організація результату**: файли розкладаються по цільових папках кластерів.

Чому цей підхід:

- **Не pHash/dHash як головний метод**: хеші добре працюють для near-duplicate, але слабкі для стабільного групування складної варіативності.
- **Не K-Means як базовий метод**: потрібно знати кількість кластерів наперед.
- **DINOv2 / ResNet + HDBSCAN**: дає гнучкий пошук структури з автоматичним виділенням шуму.
- **Dual-pass (`polarity_invariant`)**: зменшує вплив інверсії контрасту, якщо вона є у вхідних даних.

## Структура проєкту

```
.
├── main.py                 # Точка входу, оркестрація пайплайну
├── config.yaml             # Конфігурація (всі параметри)
├── requirements.txt        # Python-залежності
├── README.md               # Ця документація
└── src/
    ├── config.py           # Dataclass'и конфігурації, валідація, завантаження YAML
    ├── image_scanner.py    # Рекурсивний пошук зображень
    ├── feature_extractor.py# Витягування ознак (DINOv2/ResNet), препроцесинг, кеш
    ├── reducer.py          # PCA + UMAP зменшення розмірності
    ├── clusterer.py        # HDBSCAN кластеризація
    ├── organizer.py        # Копіювання/переміщення файлів + анотації
    └── visualizer.py       # Інтерактивний 3D scatter, сітки, графіки
```

### Вихідна структура (з анотаціями)

```
output_dir/
├── cluster_000/
│   ├── img/
│   │   ├── image_001.jpg
│   │   └── image_002.jpg
│   └── lab/
│       ├── image_001.txt
│       └── image_002.txt
├── cluster_001/
│   ├── img/
│   └── lab/
├── ...
└── viz/
    ├── interactive_scatter.html
    ├── cluster_grid.png
    ├── cluster_sizes.png
    └── preprocessing_comparison.png
```

### Вихідна структура (без анотацій)

```
output_dir/
├── cluster_000/
│   ├── image_001.jpg
│   └── image_002.jpg
├── cluster_001/
├── ...
└── viz/
```

## Конфігурація

Усі параметри задаються у файлі `config.yaml`. Нижче описано кожен параметр, його значення за замовчуванням та рекомендації.

### Важливі та чутливі параметри

Ці параметри найсильніше впливають на стабільність кластерів і мають тюнитися в першу чергу:

| Параметр | Що контролює | Типовий ефект при збільшенні | Ризик занадто великого значення |
|---|---|---|---|
| `model.image_size` | Рівень деталізації ознак | Краще розрізнення схожих сцен | Різке зростання часу inference і VRAM |
| `preprocessing.polarity_invariant` | Інваріантність до інверсії контрасту | Стабільніші ознаки при різній полярності | ~2x час витягування ознак |
| `reduction.umap_n_neighbors` | Локальність/глобальність структури UMAP | Менше дроблення на дрібні локальні групи | Можливе злипання близьких, але різних груп |
| `reduction.umap_components` | Ємність UMAP-простору | Більше інформації для HDBSCAN | Слабша щільність, більше нестабільних меж |
| `clustering.min_cluster_size` | Мінімальний розмір валідного кластера | Менше дрібних кластерів | Перекидання багатьох точок у noise |
| `clustering.cluster_selection_epsilon` | Агресивність злиття близьких підкластерів | Менше фрагментації | Надмірне об'єднання різних груп |
| `purity.max_centroid_cosine` | Межа подібності центрів кластерів | Суворіший контроль витоку між групами | Часті FAIL навіть для практично придатних результатів |
| `purity.max_nn_cross_ratio` | Частка “чужих” сусідів у kNN | Сильніша вимога локальної ізоляції | Надмірна чутливість до шуму і меж |
| `purity.min_silhouette` | Вимога до глобального розділення | Вища середня роздільність кластерів | Нестабільність на складних/нерівномірних даних |

### Вхід / Вихід

| Параметр | Тип | За замовчуванням | Опис |
|---|---|---|---|
| `input_dir` | string | `""` | Шлях до папки із зображеннями. Може містити підпапки — скрипт рекурсивно знайде всі зображення і об'єднає в один пул. |
| `output_dir` | string | `""` | Шлях куди будуть розкладені зображення. Створюється автоматично. Всередині: `cluster_000/`, `cluster_001/`, ..., та `viz/` для візуалізацій. |
| `mode` | string | `"copy"` | Режим переміщення файлів. `"copy"` — копіює (оригінали залишаються). `"move"` — переміщує (оригінали видаляються зі старого місця). |
| `image_extensions` | list[string] | `[".jpg", ".jpeg", ".png", ".bmp", ".tiff"]` | Розширення файлів, які вважаються зображеннями. Регістр ігнорується. |

### Модель

Секція `model:` контролює нейронну мережу для витягування ознак.

| Параметр | Тип | За замовчуванням | Опис |
|---|---|---|---|
| `model.name` | string | `"dinov2_vits14"` | Яку модель використовувати. Варіанти: `"dinov2_vits14"` — DINOv2 ViT-Small (384-dim, швидка), `"dinov2_vitb14"` — DINOv2 ViT-Base (768-dim, точніша), `"resnet50"` — ResNet50 (2048-dim, найлегша). ViT-B рекомендована для GPU з ≥8 GB VRAM. |
| `model.batch_size` | int | `32` | Кількість зображень в одному батчі при inference. Більше — швидше, але потребує більше VRAM. Рекомендації для ViT-B@518: RTX 4090 (24 GB) → 48–64, RTX 3080 (10 GB) → 16–24, CPU → 8. |
| `model.image_size` | int | `224` | Розмір зображення (px) при подачі в модель. DINOv2 працює з будь-яким розміром, кратним 14. 518 (37×14) — нативна роздільна здатність DINOv2 (найкращі ознаки), 448 (32×14) — компроміс, 224 — стандарт (найшвидше, але найменш точно). |
| `model.device` | string | `"auto"` | Пристрій для обчислень. `"auto"` — GPU якщо є, інакше CPU. `"cuda"` — примусово GPU. `"cpu"` — примусово CPU. |

#### Як обрати модель

- **dinov2_vitb14** + image_size **518** — максимальна якість, рекомендовано для GPU ≥ 10 GB.
- **dinov2_vits14** + image_size **518** — гарний компроміс для GPU 6–8 GB.
- **dinov2_vits14** + image_size **224** — для слабких GPU або великих батчів.
- **resnet50** — fallback якщо DINOv2 не завантажується (потребує інтернет для hub.load).

### Препроцесинг

Секція `preprocessing:` критично важлива для стабільності ознак. Її мета — зменшити вплив фотометричних варіацій (контраст, яскравість, інверсія), щоб кластеризація більше спиралась на структуру сцени.

| Параметр | Тип | За замовчуванням | Опис |
|---|---|---|---|
| `preprocessing.clahe` | bool | `true` | Увімкнення CLAHE (Contrast Limited Adaptive Histogram Equalization). Нормалізує локальний контраст і вирівнює умови між кадрами. |
| `preprocessing.clahe_clip_limit` | float | `3.0` | Обмеження контрасту для CLAHE. Діапазон 1.0–5.0. Менше (1.0–2.0) — м'якше вирівнювання, більше деталей; більше (3.0–5.0) — сильніше вирівнювання, менше фотометричного шуму. |
| `preprocessing.clahe_grid_size` | int | `8` | Розмір сітки для локальної нормалізації. 8 — стандарт. 16 — більш глобальна нормалізація. |
| `preprocessing.polarity_invariant` | bool | `true` | Dual-pass витягування ознак. Для кожного зображення витягуються ознаки з оригіналу та з інвертованої копії (255 − pixel), потім усереднюються. Це робить ознаки стійкими до інверсії полярності/контрасту. Подвоює час витягування. |
| `preprocessing.l2_normalize` | bool | `true` | L2-нормалізація вектора ознак. Перетворює вектор на одиничний, прибираючи вплив магнітуди (яка корелює з яскравістю). Кластеризація фокусується на напрямку вектора = структурі сцени. **Рекомендовано `true` завжди.** |
| `preprocessing.trim_top` | float | `0.0` | Обрізка верхнього краю зображення (частка, 0.0–1.0). Корисно для видалення службового OSD/рамок. Наприклад, `0.05` обріже верхні 5%. |
| `preprocessing.trim_bottom` | float | `0.0` | Обрізка нижнього краю зображення. |
| `preprocessing.trim_left` | float | `0.0` | Обрізка лівого краю зображення. |
| `preprocessing.trim_right` | float | `0.0` | Обрізка правого краю зображення. |

#### Як працює dual-pass

```
Зображення X
    ├── Варіант A: grayscale(X) → CLAHE → RGB → Model → features_A
    └── Варіант B: 255 − grayscale(X) → CLAHE → RGB → Model → features_B

Фінальний вектор = (features_A + features_B) / 2

Для інвертованого зображення (255 − X):
    ├── Варіант A: grayscale(255−X) → CLAHE → RGB → Model → features_B  (!)
    └── Варіант B: 255 − grayscale(255−X) = grayscale(X) → CLAHE → RGB → Model → features_A  (!)

Фінальний вектор = (features_B + features_A) / 2 = той самий результат
```

### Зменшення розмірності

Секція `reduction:` контролює двоетапне зменшення розмірності вектора ознак.

| Параметр | Тип | За замовчуванням | Опис |
|---|---|---|---|
| `reduction.pca_components` | int | `50` | Кількість компонент PCA. Перший етап — лінійне зменшення. Для ViT-B (768-dim) рекомендовано 100, для ViT-S (384-dim) — 50. Прибирає шум та корельовані ознаки. |
| `reduction.umap_components` | int | `10` | Кількість компонент UMAP. Другий етап — нелінійне зменшення. 3–5 — чисті кластери для HDBSCAN. 8–10 — більше інформації, але менш чіткі межі. Рекомендовано 5. |
| `reduction.umap_n_neighbors` | int | `15` | Кількість сусідів для UMAP. Контролює баланс локальної/глобальної структури. 5–10 — більше локальних деталей. 30–50 — більше глобальної стабільності. |
| `reduction.umap_min_dist` | float | `0.1` | Мінімальна відстань між точками в UMAP-просторі. 0.0 — максимально щільні кластери (найкраще для HDBSCAN). 0.1–0.5 — розпушені (для візуалізації). |
| `reduction.umap_metric` | string | `"cosine"` | Метрика відстані для UMAP. `"cosine"` — рекомендована для NN-ознак (порівнює напрямок вектора). `"euclidean"` — евклідова відстань. |

#### PCA + UMAP: навіщо два етапи

PCA прибирає лінійний шум і зменшує розмірність до ~100. UMAP потім робить нелінійну проекцію, зберігаючи топологічну структуру. Подавати UMAP напряму 768-dim вектор можна, але повільно і шумно.

### Кластеризація

Секція `clustering:` контролює HDBSCAN.

| Параметр | Тип | За замовчуванням | Опис |
|---|---|---|---|
| `clustering.min_cluster_size` | int | `50` | Мінімальна кількість зображень для формування кластера. Менше цього — вважається шумом. Для датасету 10K–100K зазвичай стартують з 50–300. |
| `clustering.min_samples` | int | `10` | Кількість сусідів для оцінки щільності. Більше — консервативніша кластеризація (менше дрібних кластерів, більше шуму). Менше — агресивніша. Має бути ≤ `min_cluster_size`. |
| `clustering.cluster_selection_epsilon` | float | `0.0` | Порогова відстань для злиття кластерів всередині HDBSCAN. 0.0 — стандартна поведінка. Більше 0 — зливає кластери, центри яких ближчі за цю відстань в UMAP-просторі. 0.3–0.5 часто зменшує фрагментацію. |
| `clustering.cluster_selection_method` | string | `"leaf"` | Метод вибору кластерів. `"eom"` (Excess of Mass) — стандарт, кластери різного розміру. `"leaf"` — дрібніші й однорідніші кластери. |
| `clustering.noise_handling` | string | `"nearest"` | Що робити з шумовими точками (-1). `"separate"` — окрема папка `noise/`. `"nearest"` — призначає до найближчого кластера за евклідовою відстанню до центроїда. |

#### Стратегія налаштування кластеризації

1. Запустіть з параметрами за замовчуванням та подивіться скільки кластерів знайде HDBSCAN.
2. Якщо їх забагато (HDBSCAN перерозбиває) — збільшіть `cluster_selection_epsilon` (0.3 → 0.5 → 0.8) або спробуйте `cluster_selection_method: "eom"`.
3. Якщо занадто мало — зменшіть `min_cluster_size` або `cluster_selection_epsilon`.
4. `min_samples` впливає на «чутливість» до щільності: менше — більше кластерів, більше — менше кластерів і більше шуму.

### Візуалізація

Секція `visualization:` контролює генерацію діагностичних візуалізацій.

| Параметр | Тип | За замовчуванням | Опис |
|---|---|---|---|
| `visualization.enabled` | bool | `true` | Чи генерувати візуалізації. Якщо `false`, крок 6 пропускається. |
| `visualization.viz_dir` | string | `"viz"` | Підпапка для візуалізацій (відносно `output_dir`). |
| `visualization.max_points` | int | `5000` | Максимум точок на інтерактивному scatter-графіку. Для датасетів > цього числа робиться випадкова вибірка. 5000 — комфортно в браузері. |
| `visualization.thumbnail_size` | int | `80` | Розмір мініатюри (px) для hover-превью. 64–96 достатньо. Більше — важчий HTML-файл. |
| `visualization.samples_per_cluster` | int | `16` | Кількість зразків на кластер для статичної сітки `cluster_grid.png`. Більше — повніша картина, але файл більший. |
| `visualization.clahe_comparison_samples` | int | `8` | Кількість зразків для порівняння препроцесингу. Показує оригінал, CLAHE(normal), CLAHE(inverted) для різних кластерів. |

### Анотації (YOLO)

Секція `annotations:` контролює перенос анотацій разом з зображеннями.

| Параметр | Тип | За замовчуванням | Опис |
|---|---|---|---|
| `annotations.enabled` | bool | `true` | Чи переносити YOLO-анотації. Якщо `true`, створюються підпапки `img/` та `lab/` всередині кожного кластера. Якщо `false` — зображення кладуться напряму в `cluster_NNN/`. |
| `annotations.image_subdir` | string | `"img"` | Назва підпапки з зображеннями у вхідних даних. Скрипт шукає цю назву в шляху зображення і замінює на `label_subdir` для пошуку анотації. |
| `annotations.label_subdir` | string | `"lab"` | Назва підпапки з анотаціями у вхідних даних. |
| `annotations.label_extension` | string | `".txt"` | Розширення файлів анотацій. Стандартно `.txt` для YOLO-формату. |

#### Як знаходяться анотації

Для зображення `D:/data/source_01/img/frame_001.jpg` скрипт:
1. Знаходить `img` у шляху
2. Замінює на `lab` → `D:/data/source_01/lab/frame_001.txt`
3. Якщо файл існує — переносить разом із зображенням

Пошук йде від кінця шляху, тому працює навіть якщо `img` зустрічається кілька разів.

### Кешування

Секція `cache:` дозволяє зберігати витягнуті ознаки на диск.

| Параметр | Тип | За замовчуванням | Опис |
|---|---|---|---|
| `cache.enabled` | bool | `true` | Чи кешувати ознаки. Якщо `true`, при повторному запуску з тими ж зображеннями та моделлю пропускається найдовший етап (inference). |
| `cache.cache_dir` | string | `".cache"` | Папка для збереження кешу. Ключ кешу — SHA256 від списку файлів + параметри моделі/препроцесингу. |

**Коли потрібно видалити кеш**: при зміні будь-якого параметра препроцесингу (`clahe`, `polarity_invariant`, `clahe_clip_limit`, `clahe_grid_size`, `l2_normalize`, `trim_*`) або моделі (`name`, `image_size`). Зміна параметрів кластеризації (`min_cluster_size`, `cluster_selection_epsilon`, ...) або UMAP **не потребує** перерахунку ознак — кеш буде використано.

### Прискорення (CPU/CUDA)

Секція `acceleration:` керує backend для етапів:

- `PCA + UMAP` (reduction)
- `HDBSCAN` (clustering)
- `purity` метрики (`silhouette`, kNN, матриці)

| Параметр | Тип | За замовчуванням | Опис |
|---|---|---|---|
| `acceleration.backend` | string | `"auto"` | `"auto"` — спроба CUDA (RAPIDS cuML) з fallback на CPU; `"cuda"` — пріоритет CUDA з fallback на CPU при недоступності; `"cpu"` — примусово CPU. |

Важливо:

- PyTorch (етап features) використовує `model.device`.
- `acceleration.backend` впливає на reduction/clustering/purity.
- Якщо CUDA-бібліотеки RAPIDS не встановлені, скрипт автоматично перейде на CPU і виведе warning.

#### Рекомендоване встановлення RAPIDS у WSL2 (Ubuntu)

1) Створіть окреме середовище RAPIDS:

```bash
conda create -n rapids-25.10 -c rapidsai -c conda-forge -c nvidia rapids=25.10 python=3.10 cuda-version=12.5
conda activate rapids-25.10
```

2) Встановіть залежності тюнінгу (безпечний варіант для RAPIDS env):

```bash
pip install -r requirements_rapids_tuning.txt
```

`requirements_rapids_tuning.txt` навмисно не містить `torch/torchvision`, щоб не ламати RAPIDS CUDA-залежності.

3) Налаштуйте Linux-шляхи у `config.yaml`:

- `input_dir: "/mnt/d/datasets_images/dataset"`
- `output_dir: "/mnt/d/dataset_filtered_by_presets"`

4) Увімкніть auto backend:

```yaml
acceleration:
  backend: "auto"
```

#### 3 команди перевірки GPU (RAPIDS + PyTorch)

```bash
python -c "import cupy as cp, cuml; print('cuML', cuml.__version__); print('CUDA devices', cp.cuda.runtime.getDeviceCount()); print('GPU', cp.cuda.runtime.getDeviceProperties(0)['name'])"
```

```bash
python -c "from cuml.decomposition import PCA; from cuml.manifold import UMAP; from cuml.cluster import HDBSCAN; import cupy as cp, numpy as np; X=cp.random.random((20000,64),dtype=cp.float32); Z=PCA(n_components=16).fit_transform(X); E=UMAP(n_components=3,n_neighbors=30,min_dist=0.0).fit_transform(Z); y=HDBSCAN(min_cluster_size=50).fit_predict(E); print('OK', int(np.sum(cp.asnumpy(y!=-1))))"
```

```bash
python -c "import torch; print('torch', torch.__version__); print('cuda', torch.cuda.is_available()); print('device', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'none')"
```

#### Важливо про `pip install torch` у RAPIDS env

Не рекомендується ставити `torch/torchvision` через `pip` поверх RAPIDS-середовища, бо це може перезаписати CUDA-залежності (`cuda-bindings`, `cuda-python`) і зламати `cupy/cuml`.

Якщо так сталося:

- найнадійніше — створити нове чисте `conda` середовище RAPIDS заново;
- або тримати окреме env для feature extraction (PyTorch) і окреме env для RAPIDS-тюнінгу.

## Візуалізації

### interactive_scatter.html

Інтерактивний 3D scatter plot (Plotly). Кожна точка — зображення, колір — кластер. На бічній панелі при наведенні курсора показується мініатюра зображення та метадані.

Керування:
- **Обертання**: ЛКМ + тягнути
- **Зум**: колесо миші
- **Переміщення**: ПКМ + тягнути
- Кнопка «Скинути вид» повертає вид за замовчуванням
- Кнопка «Авто-обертання» вмикає повільне обертання сцени

### cluster_grid.png

Статична сітка з вибіркою зображень кожного кластера. Дозволяє швидко оцінити якість кластеризації — чи дійсно кожен кластер є візуально однорідним.

### cluster_sizes.png

Стовпчикова діаграма кількості зображень у кожному кластері. Дозволяє побачити баланс і виявити аномально великі/малі кластери.

### preprocessing_comparison.png

Порівняння препроцесингу: оригінал → CLAHE(normal) → CLAHE(inverted). Показує, що саме «бачить» модель при dual-pass.

## Ітеративний тюнінг (`iterative_tuning.py`)

Окремий модуль у корені проєкту для масового пошуку гіперпараметрів з автоматичним запуском reduction + clustering + purity на кожній ітерації.

### Навігація по розділу

- [Для чого потрібен](#для-чого-потрібен)
- [Життєвий цикл запуску](#життєвий-цикл-запуску)
- [Алгоритм пошуку (grid / evolution)](#алгоритм-пошуку-grid--evolution)
- [Двофазний режим](#двофазний-режим)
- [Early stop (плато)](#early-stop-плато)
- [Як інтерпретувати метрики](#як-інтерпретувати-метрики)
- [Артефакти та звітність](#артефакти-та-звітність)

### Для чого потрібен

- Виконувати сотні і тисячі прогонів без ручного втручання.
- Системно знаходити стабільні області гіперпараметрів замість ручного підбору.
- Автоматично відкидати слабкі конфіги за purity-метриками.
- Отримувати відтворюваний журнал, графіки та фінальний shortlist.

### Запуск

```bash
python iterative_tuning.py
```

Базовий конфіг завантажується з `config.yaml` (через `BASE_CONFIG_PATH`), а параметри з `SEARCH_SPACE` накладаються як `overrides`.

### Життєвий цикл запуску

1. Завантаження базового конфіга і побудова/читання кешу індексу зображень.
2. Формування кандидатів (grid або evolution).
3. Для кожного кандидата:
   - збір runtime-конфіга,
   - reduction (`PCA + UMAP`),
   - clustering (`HDBSCAN`),
   - purity-оцінка (`max_centroid_cosine`, `silhouette`, `max_nn_cross_ratio`),
   - розрахунок підсумкового score для ранжування.
4. Збереження артефактів і метрик ітерації.
5. Оновлення глобального рейтингу (`best`, `top20`, `all_results`).
6. Якщо увімкнено `GENERATE_FULL_VISUALS_FOR_TOP_N` — повторний повний прогін топ-кандидатів з усіма візуалізаціями.

### Алгоритм пошуку (grid / evolution)

- `SEARCH_STRATEGY = "grid"`:
  - рівномірно перебирає поєднання з `SEARCH_SPACE`,
  - добре для контрольованого локального аналізу,
  - дорожче при великому просторі.
- `SEARCH_STRATEGY = "evolution"`:
  - працює популяціями (best + crossover + mutation),
  - швидше знаходить сильні конфіги при обмеженому бюджеті,
  - краще масштабується на великі простори.

Що можна тюнити:

- `reduction.umap_components`
- `reduction.umap_n_neighbors`
- `clustering.min_cluster_size`
- `clustering.min_samples`
- `clustering.cluster_selection_epsilon`
- `clustering.cluster_selection_method`
- будь-який інший ключ формату `section.param`, якщо доданий у `SEARCH_SPACE`.

### Двофазний режим

Ключі:
- `TWO_PHASE_ENABLED`
- `PHASE1_FRACTION`
- `PHASE1_BUDGET_RATIO`
- `PHASE2_TOP_K_SEEDS`

Логіка:

1. **Фаза 1 (швидка)**: пошук на частині даних (`PHASE1_FRACTION`).
2. **Фаза 2 (точна)**: пошук/дооцінка на повному наборі, стартуючи з найкращих кандидатів фази 1.

Практичний ефект: менше часу на явно слабкі зони простору, більше обчислень на перспективні конфіги.

### Early stop (плато)

Ключі:
- `EARLY_STOP_ENABLED`
- `EARLY_STOP_PATIENCE_GENERATIONS`
- `EARLY_STOP_MIN_EVALUATIONS`

Фаза вважається на плато, коли після `EARLY_STOP_MIN_EVALUATIONS` найкращий score не покращується протягом `EARLY_STOP_PATIENCE_GENERATIONS` поколінь. У такому випадку фаза завершується достроково.

### Як інтерпретувати метрики

- `max_centroid_cosine`:
  - максимально близька пара центрів кластерів,
  - **менше = краще** (кластери більш розділені між собою).
- `silhouette`:
  - глобальна якість розділення “свій кластер проти сусідніх”,
  - **більше = краще**.
- `max_nn_cross_ratio`:
  - найбільша частка “чужих” сусідів у kNN для кластера,
  - **менше = краще**.
- `verdict`:
  - `PASS`, якщо виконані пороги purity;
  - `FAIL`, якщо хоча б один поріг порушено.

### Артефакти та звітність

- Поточний лог: stdout у консолі (деталізація керується `CONSOLE_VERBOSITY` і `DETAILED_FIRST_N_ITERS`).
- Артефакти ітерацій: `output_dir/_tuning/<iteration_name>/...`
  - `viz/purity_report_latest.json`
  - `viz/centroid_cosine_matrix.npy`
- Агрегований підсумок:
  - `output_dir/_tuning/tuning_summary_latest.json`
  - `output_dir/_tuning/tuning_results_all.csv`
- Кеш індексу:
  - `./.cache/image_index_<hash_input_dir>.json`

Що очікувати від запуску:

- На перших ітераціях — детальні логи для перевірки коректності.
- Далі — компактний режим для довгих прогонів.
- Наприкінці — готовий рейтинг кандидатів і файли для відтворення будь-якої ітерації.

## Поради з налаштування

### Типовий сценарій: складні дані з високою фотометричною варіативністю

```yaml
model:
  name: "dinov2_vitb14"
  image_size: 518
  batch_size: 48        # для RTX 4090; менше для слабших GPU

preprocessing:
  clahe: true
  clahe_clip_limit: 3.0
  polarity_invariant: true
  l2_normalize: true
  trim_top: 0.03          # обрізка OSD (дата/час зверху)
  trim_bottom: 0.03       # обрізка OSD знизу

reduction:
  pca_components: 100
  umap_components: 5
  umap_n_neighbors: 30
  umap_min_dist: 0.0
  umap_metric: "cosine"

clustering:
  min_cluster_size: 200   # підлаштувати під розмір датасету
  min_samples: 2
  cluster_selection_epsilon: 0.5
  cluster_selection_method: "leaf"
  noise_handling: "nearest"
```

### Типовий сценарій: стабільні дані зі слабкою варіативністю

```yaml
model:
  name: "dinov2_vitb14"
  image_size: 518

preprocessing:
  clahe: false
  polarity_invariant: false
  l2_normalize: true

reduction:
  pca_components: 100
  umap_components: 5
  umap_n_neighbors: 30
  umap_min_dist: 0.0
  umap_metric: "cosine"

clustering:
  min_cluster_size: 100
  min_samples: 5
  cluster_selection_epsilon: 0.3
  cluster_selection_method: "eom"
  noise_handling: "nearest"
```

### Якщо HDBSCAN знаходить забагато кластерів

1. Збільшити `cluster_selection_epsilon` (0.3 → 0.5 → 0.8)
2. Збільшити `min_cluster_size`
3. Спробувати `cluster_selection_method: "eom"`
4. Зменшити `umap_components` (5 → 3)

### Якщо HDBSCAN знаходить замало кластерів

1. Зменшити `min_cluster_size` (200 → 100 → 50)
2. Зменшити `cluster_selection_epsilon` (0.5 → 0.0)
3. Збільшити `min_samples` (2 → 5 → 10)
4. Збільшити `umap_components` (5 → 8)
5. Зменшити `umap_n_neighbors` (30 → 15)

### Якщо один кластер містить кілька різних сцен

Це означає, що модель не бачить різниці між ними. Можливі дії:
1. Збільшити `image_size` (224 → 518) для кращих ознак
2. Перейти на більшу модель (`vits14` → `vitb14`)
3. Зменшити `cluster_selection_epsilon`
4. Зменшити `min_cluster_size`
5. Збільшити `umap_n_neighbors` для кращої глобальної структури

### Швидкість: чого очікувати

Для датасету ~10 000 зображень з RTX 4090:
- Витягування ознак (ViT-B@518, dual-pass): ~3–5 хв
- PCA + UMAP: ~30 сек
- HDBSCAN: ~3 сек
- Візуалізації: ~1–2 хв
- Повторний запуск (з кешу): ~2 хв (без inference)
