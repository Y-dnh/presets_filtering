# Фільтрація датасету за пресетами камер

Інструмент для автоматичного розподілу зображень з PTZ-камер (зокрема тепловізійних) по папках за кутами огляду (пресетами). Використовує нейронну мережу для витягування ознак, зменшення розмірності та density-based кластеризацію — кількість пресетів визначається автоматично.

## Зміст

- [Встановлення](#встановлення)
- [Запуск](#запуск)
- [Як працює](#як-працює)
- [Структура проєкту](#структура-проєкту)
- [Конфігурація](#конфігурація)
  - [Вхід / Вихід](#вхід--вихід)
  - [Модель](#модель)
  - [Препроцесинг](#препроцесинг)
  - [Зменшення розмірності](#зменшення-розмірності)
  - [Кластеризація](#кластеризація)
  - [Візуалізація](#візуалізація)
  - [Анотації (YOLO)](#анотації-yolo)
  - [Кешування](#кешування)
- [Візуалізації](#візуалізації)
- [Поради з налаштування](#поради-з-налаштування)

## Встановлення

Потрібен Python 3.10+ та NVIDIA GPU (рекомендовано, але не обов'язково).

```bash
# Створення віртуального середовища
python -m venv venv
venv\Scripts\activate        # Windows
# source venv/bin/activate   # Linux/macOS

# Встановлення залежностей
pip install -r requirements.txt
```

### Залежності

| Пакет | Призначення |
|---|---|
| `torch`, `torchvision` | Нейронна мережа (inference) |
| `Pillow` | Завантаження зображень |
| `opencv-python` | CLAHE, конвертація кольорів |
| `scikit-learn` | PCA, NearestCentroid |
| `umap-learn` | UMAP (зменшення розмірності) |
| `hdbscan` | Density-based кластеризація |
| `numpy` | Матричні операції |
| `pyyaml` | Парсинг конфігурації |
| `tqdm` | Прогрес-бари |
| `matplotlib` | Статичні візуалізації (графіки, сітки) |

PyTorch встановлюється через `requirements.txt`. Для GPU-прискорення переконайтесь, що встановлена версія з підтримкою CUDA (див. [pytorch.org](https://pytorch.org/get-started/locally/)).

## Запуск

```bash
# З конфігурацією за замовчуванням (config.yaml в поточній директорії)
python main.py

# З іншим файлом конфігурації
python main.py --config path/to/my_config.yaml
```

Програма виконує 7 кроків послідовно:

1. Завантаження конфігурації
2. Рекурсивне сканування зображень
3. Витягування ознак нейронною мережею (або з кешу)
4. Зменшення розмірності (PCA + UMAP)
5. Кластеризація (HDBSCAN)
6. Генерація візуалізацій
7. Підтвердження від користувача і розкладання файлів по папках

Перед переміщенням/копіюванням файлів програма виводить таблицю з кількістю знайдених пресетів та зображень у кожному, і чекає підтвердження (`y`/`n`).

## Як працює

### Пайплайн

```
Зображення (папка)
      │
      ▼
┌─────────────────┐
│ Препроцесинг    │  Grayscale → [Invert] → CLAHE → RGB
│                 │  (два варіанти при polarity_invariant)
└────────┬────────┘
         ▼
┌─────────────────┐
│ Нейронна мережа │  DINOv2 ViT-B/14 → 768-dim вектор ознак
│                 │  (усереднення normal + inverted при dual-pass)
└────────┬────────┘
         ▼
┌─────────────────┐
│ L2-нормалізація │  Прибирає вплив магнітуди → unit vector
└────────┬────────┘
         ▼
┌─────────────────┐
│ PCA             │  768 → 100 dim (лінійне зменшення, шумозаглушення)
└────────┬────────┘
         ▼
┌─────────────────┐
│ UMAP            │  100 → 5 dim (нелінійне, зберігає структуру)
└────────┬────────┘
         ▼
┌─────────────────┐
│ HDBSCAN         │  Density-based кластеризація → мітки кластерів
└────────┬────────┘
         ▼
┌─────────────────┐
│ Організація     │  Копіювання/переміщення по папках preset_NNN/
│ файлів          │  + перенос YOLO-анотацій (img/ + lab/)
└─────────────────┘
```

### Чому саме такий підхід

**Проблема**: PTZ-камера робить знімки з кількох фіксованих кутів огляду (пресетів). Потрібно автоматично визначити, яке зображення до якого пресету належить, без знання точної кількості пресетів.

**Чому не pHash/dHash**: Перцептивні хеші чутливі до зміни яскравості та контрасту, що для тепловізора змінюється постійно (доба, температура, полярність white-hot/black-hot).

**Чому не K-Means**: Потребує заданої кількості кластерів, яку ми не знаємо. HDBSCAN визначає кількість кластерів автоматично на основі щільності.

**Чому DINOv2**: Самонавчальна (self-supervised) модель, яка витягує структурні ознаки зображення (контури, лінії, форми) незалежно від кольору. Це ідеально для тепловізійних зображень.

**Чому dual-pass**: Тепловізійні камери можуть працювати у режимі white-hot або black-hot — одна сцена виглядає як негатив іншої. Dual-pass гарантує ідентичний вектор ознак для обох полярностей: `f(img) == f(255 - img)`.

## Структура проєкту

```
.
├── main.py                 # Точка входу, оркестрація пайплайну
├── config.yaml             # Конфігурація (всі параметри)
├── requirements.txt        # Python-залежності
├── README.md               # Ця документація
└── src/
    ├── config.py           # Dataclass'и конфігурації, валідація, завантаження YAML
    ├── image_scanner.py    # Рекурсивний пошук зображень
    ├── feature_extractor.py# Витягування ознак (DINOv2/ResNet), препроцесинг, кеш
    ├── reducer.py          # PCA + UMAP зменшення розмірності
    ├── clusterer.py        # HDBSCAN кластеризація
    ├── organizer.py        # Копіювання/переміщення файлів + анотації
    └── visualizer.py       # Інтерактивний 3D scatter, сітки, графіки
```

### Вихідна структура (з анотаціями)

```
output_dir/
├── preset_000/
│   ├── img/
│   │   ├── image_001.jpg
│   │   └── image_002.jpg
│   └── lab/
│       ├── image_001.txt
│       └── image_002.txt
├── preset_001/
│   ├── img/
│   └── lab/
├── ...
└── viz/
    ├── interactive_scatter.html
    ├── cluster_grid.png
    ├── cluster_sizes.png
    └── preprocessing_comparison.png
```

### Вихідна структура (без анотацій)

```
output_dir/
├── preset_000/
│   ├── image_001.jpg
│   └── image_002.jpg
├── preset_001/
├── ...
└── viz/
```

## Конфігурація

Усі параметри задаються у файлі `config.yaml`. Нижче описано кожен параметр, його значення за замовчуванням та рекомендації.

### Вхід / Вихід

| Параметр | Тип | За замовчуванням | Опис |
|---|---|---|---|
| `input_dir` | string | `""` | Шлях до папки із зображеннями. Може містити підпапки — скрипт рекурсивно знайде всі зображення і об'єднає в один пул. Усі підпапки (камери) кластеризуються разом, оскільки пресети з різних камер можуть перетинатися. |
| `output_dir` | string | `""` | Шлях куди будуть розкладені зображення. Створюється автоматично. Всередині: `preset_000/`, `preset_001/`, ..., та `viz/` для візуалізацій. |
| `mode` | string | `"copy"` | Режим переміщення файлів. `"copy"` — копіює (оригінали залишаються). `"move"` — переміщує (оригінали видаляються зі старого місця). |
| `image_extensions` | list[string] | `[".jpg", ".jpeg", ".png", ".bmp", ".tiff"]` | Розширення файлів, які вважаються зображеннями. Регістр ігнорується. |

### Модель

Секція `model:` контролює нейронну мережу для витягування ознак.

| Параметр | Тип | За замовчуванням | Опис |
|---|---|---|---|
| `model.name` | string | `"dinov2_vits14"` | Яку модель використовувати. Варіанти: `"dinov2_vits14"` — DINOv2 ViT-Small (384-dim, швидка), `"dinov2_vitb14"` — DINOv2 ViT-Base (768-dim, точніша), `"resnet50"` — ResNet50 (2048-dim, найлегша). ViT-B рекомендована для GPU з ≥8 GB VRAM. |
| `model.batch_size` | int | `32` | Кількість зображень в одному батчі при inference. Більше — швидше, але потребує більше VRAM. Рекомендації для ViT-B@518: RTX 4090 (24 GB) → 48–64, RTX 3080 (10 GB) → 16–24, CPU → 8. |
| `model.image_size` | int | `224` | Розмір зображення (px) при подачі в модель. DINOv2 працює з будь-яким розміром, кратним 14. 518 (37×14) — нативна роздільна здатність DINOv2 (найкращі ознаки), 448 (32×14) — компроміс, 224 — стандарт (найшвидше, але найменш точно). |
| `model.device` | string | `"auto"` | Пристрій для обчислень. `"auto"` — GPU якщо є, інакше CPU. `"cuda"` — примусово GPU. `"cpu"` — примусово CPU. |

#### Як обрати модель

- **dinov2_vitb14** + image_size **518** — максимальна якість, рекомендовано для GPU ≥ 10 GB.
- **dinov2_vits14** + image_size **518** — гарний компроміс для GPU 6–8 GB.
- **dinov2_vits14** + image_size **224** — для слабких GPU або великих батчів.
- **resnet50** — fallback якщо DINOv2 не завантажується (потребує інтернет для hub.load).

### Препроцесинг

Секція `preprocessing:` — критично важлива для тепловізійних камер. Без препроцесингу модель «бачить» різницю в яскравості/температурі і розділяє один пресет на кілька кластерів.

| Параметр | Тип | За замовчуванням | Опис |
|---|---|---|---|
| `preprocessing.clahe` | bool | `true` | Увімкнення CLAHE (Contrast Limited Adaptive Histogram Equalization). Нормалізує контраст зображень — прибирає вплив зміни доби, температури, пори року. Залишає тільки структуру сцени. **Рекомендовано `true` для тепловізорів**, `false` для RGB-камер. |
| `preprocessing.clahe_clip_limit` | float | `3.0` | Обмеження контрасту для CLAHE. Діапазон 1.0–5.0. Менше (1.0–2.0) — слабша нормалізація, зберігає більше деталей. Більше (3.0–5.0) — агресивніша нормалізація, краще для тепловізора. |
| `preprocessing.clahe_grid_size` | int | `8` | Розмір сітки для локальної нормалізації. 8 — стандарт. 16 — більш глобальна нормалізація. |
| `preprocessing.polarity_invariant` | bool | `true` | Dual-pass витягування ознак. Для кожного зображення витягуються ознаки з оригіналу та з інвертованої копії (255 − pixel), потім усереднюються. Математично гарантує `f(img) == f(255 − img)` — ідеальна інваріантність до полярності тепловізора (white-hot / black-hot). Подвоює час витягування. **Рекомендовано `true` для тепловізорів.** |
| `preprocessing.l2_normalize` | bool | `true` | L2-нормалізація вектора ознак. Перетворює вектор на одиничний, прибираючи вплив магнітуди (яка корелює з яскравістю). Кластеризація фокусується на напрямку вектора = структурі сцени. **Рекомендовано `true` завжди.** |
| `preprocessing.trim_top` | float | `0.0` | Обрізка верхнього краю зображення (частка, 0.0–1.0). Прибирає OSD (дата, час, назва камери). Наприклад, `0.05` обріже верхні 5%. |
| `preprocessing.trim_bottom` | float | `0.0` | Обрізка нижнього краю зображення. |
| `preprocessing.trim_left` | float | `0.0` | Обрізка лівого краю зображення. |
| `preprocessing.trim_right` | float | `0.0` | Обрізка правого краю зображення. |

#### Як працює dual-pass

```
Зображення X
    ├── Варіант A: grayscale(X) → CLAHE → RGB → Model → features_A
    └── Варіант B: 255 − grayscale(X) → CLAHE → RGB → Model → features_B

Фінальний вектор = (features_A + features_B) / 2

Для інвертованого зображення (255 − X):
    ├── Варіант A: grayscale(255−X) → CLAHE → RGB → Model → features_B  (!)
    └── Варіант B: 255 − grayscale(255−X) = grayscale(X) → CLAHE → RGB → Model → features_A  (!)

Фінальний вектор = (features_B + features_A) / 2 = той самий результат
```

### Зменшення розмірності

Секція `reduction:` контролює двоетапне зменшення розмірності вектора ознак.

| Параметр | Тип | За замовчуванням | Опис |
|---|---|---|---|
| `reduction.pca_components` | int | `50` | Кількість компонент PCA. Перший етап — лінійне зменшення. Для ViT-B (768-dim) рекомендовано 100, для ViT-S (384-dim) — 50. Прибирає шум та корельовані ознаки. |
| `reduction.umap_components` | int | `10` | Кількість компонент UMAP. Другий етап — нелінійне зменшення. 3–5 — чисті кластери для HDBSCAN. 8–10 — більше інформації, але менш чіткі межі. Рекомендовано 5. |
| `reduction.umap_n_neighbors` | int | `15` | Кількість сусідів для UMAP. Контролює баланс локальної/глобальної структури. 5–10 — більше локальних деталей. 30–50 — більше глобальної структури (рекомендовано для пресетів). |
| `reduction.umap_min_dist` | float | `0.1` | Мінімальна відстань між точками в UMAP-просторі. 0.0 — максимально щільні кластери (найкраще для HDBSCAN). 0.1–0.5 — розпушені (для візуалізації). |
| `reduction.umap_metric` | string | `"cosine"` | Метрика відстані для UMAP. `"cosine"` — рекомендована для NN-ознак (порівнює напрямок вектора). `"euclidean"` — евклідова відстань. |

#### PCA + UMAP: навіщо два етапи

PCA прибирає лінійний шум і зменшує розмірність до ~100. UMAP потім робить нелінійну проекцію, зберігаючи топологічну структуру. Подавати UMAP напряму 768-dim вектор можна, але повільно і шумно.

### Кластеризація

Секція `clustering:` контролює HDBSCAN.

| Параметр | Тип | За замовчуванням | Опис |
|---|---|---|---|
| `clustering.min_cluster_size` | int | `50` | Мінімальна кількість зображень для формування кластера. Менше цього — вважається шумом. Для датасету 10K–100K рекомендовано 50–300 залежно від кількості знімків на пресет. |
| `clustering.min_samples` | int | `10` | Кількість сусідів для оцінки щільності. Більше — консервативніша кластеризація (менше дрібних кластерів, більше шуму). Менше — агресивніша. Має бути ≤ `min_cluster_size`. Рекомендовано 2–5 для тепловізорів. |
| `clustering.cluster_selection_epsilon` | float | `0.0` | Порогова відстань для злиття кластерів всередині HDBSCAN. 0.0 — стандартна поведінка. Більше 0 — зливає кластери, центри яких ближчі за цю відстань в UMAP-просторі. 0.3–0.5 — допомагає злити під-кластери одного пресету (наприклад день/ніч). |
| `clustering.cluster_selection_method` | string | `"leaf"` | Метод вибору кластерів. `"eom"` (Excess of Mass) — стандарт, кластери різного розміру, може перерозбивати. `"leaf"` — листкові кластери, більш однорідні за розміром, рекомендовано для пресетів. |
| `clustering.noise_handling` | string | `"nearest"` | Що робити з шумовими точками (-1). `"separate"` — окрема папка `noise/`. `"nearest"` — призначає до найближчого кластера за евклідовою відстанню до центроїда. |

#### Стратегія налаштування кластеризації

1. Запустіть з параметрами за замовчуванням та подивіться скільки кластерів знайде HDBSCAN.
2. Якщо їх забагато (HDBSCAN перерозбиває) — збільшіть `cluster_selection_epsilon` (0.3 → 0.5 → 0.8) або спробуйте `cluster_selection_method: "eom"`.
3. Якщо занадто мало — зменшіть `min_cluster_size` або `cluster_selection_epsilon`.
4. `min_samples` впливає на «чутливість» до щільності: менше — більше кластерів, більше — менше кластерів і більше шуму.

### Візуалізація

Секція `visualization:` контролює генерацію діагностичних візуалізацій.

| Параметр | Тип | За замовчуванням | Опис |
|---|---|---|---|
| `visualization.enabled` | bool | `true` | Чи генерувати візуалізації. Якщо `false`, крок 6 пропускається. |
| `visualization.viz_dir` | string | `"viz"` | Підпапка для візуалізацій (відносно `output_dir`). |
| `visualization.max_points` | int | `5000` | Максимум точок на інтерактивному scatter-графіку. Для датасетів > цього числа робиться випадкова вибірка. 5000 — комфортно в браузері. |
| `visualization.thumbnail_size` | int | `80` | Розмір мініатюри (px) для hover-превью. 64–96 достатньо. Більше — важчий HTML-файл. |
| `visualization.samples_per_cluster` | int | `16` | Кількість зразків на кластер для статичної сітки `cluster_grid.png`. Більше — повніша картина, але файл більший. |
| `visualization.clahe_comparison_samples` | int | `8` | Кількість зразків для порівняння препроцесингу. Показує оригінал, CLAHE(normal), CLAHE(inverted) для різних кластерів. |

### Анотації (YOLO)

Секція `annotations:` контролює перенос анотацій разом з зображеннями.

| Параметр | Тип | За замовчуванням | Опис |
|---|---|---|---|
| `annotations.enabled` | bool | `true` | Чи переносити YOLO-анотації. Якщо `true`, створюються підпапки `img/` та `lab/` всередині кожного пресету. Якщо `false` — зображення кладуться напряму в `preset_NNN/`. |
| `annotations.image_subdir` | string | `"img"` | Назва підпапки з зображеннями у вхідних даних. Скрипт шукає цю назву в шляху зображення і замінює на `label_subdir` для пошуку анотації. |
| `annotations.label_subdir` | string | `"lab"` | Назва підпапки з анотаціями у вхідних даних. |
| `annotations.label_extension` | string | `".txt"` | Розширення файлів анотацій. Стандартно `.txt` для YOLO-формату. |

#### Як знаходяться анотації

Для зображення `D:/data/camera1/img/frame_001.jpg` скрипт:
1. Знаходить `img` у шляху
2. Замінює на `lab` → `D:/data/camera1/lab/frame_001.txt`
3. Якщо файл існує — переносить разом із зображенням

Пошук йде від кінця шляху, тому працює навіть якщо `img` зустрічається кілька разів.

### Кешування

Секція `cache:` дозволяє зберігати витягнуті ознаки на диск.

| Параметр | Тип | За замовчуванням | Опис |
|---|---|---|---|
| `cache.enabled` | bool | `true` | Чи кешувати ознаки. Якщо `true`, при повторному запуску з тими ж зображеннями та моделлю пропускається найдовший етап (inference). |
| `cache.cache_dir` | string | `".cache"` | Папка для збереження кешу. Ключ кешу — SHA256 від списку файлів + параметри моделі/препроцесингу. |

**Коли потрібно видалити кеш**: при зміні будь-якого параметра препроцесингу (`clahe`, `polarity_invariant`, `clahe_clip_limit`, `clahe_grid_size`, `l2_normalize`, `trim_*`) або моделі (`name`, `image_size`). Зміна параметрів кластеризації (`min_cluster_size`, `cluster_selection_epsilon`, ...) або UMAP **не потребує** перерахунку ознак — кеш буде використано.

### Прискорення (CPU/CUDA)

Секція `acceleration:` керує backend для етапів:

- `PCA + UMAP` (reduction)
- `HDBSCAN` (clustering)
- `purity` метрики (`silhouette`, kNN, матриці)

| Параметр | Тип | За замовчуванням | Опис |
|---|---|---|---|
| `acceleration.backend` | string | `"auto"` | `"auto"` — спроба CUDA (RAPIDS cuML) з fallback на CPU; `"cuda"` — пріоритет CUDA з fallback на CPU при недоступності; `"cpu"` — примусово CPU. |

Важливо:

- PyTorch (етап features) використовує `model.device`.
- `acceleration.backend` впливає на reduction/clustering/purity.
- Якщо CUDA-бібліотеки RAPIDS не встановлені, скрипт автоматично перейде на CPU і виведе warning.

#### Рекомендоване встановлення RAPIDS у WSL2 (Ubuntu)

1) Створіть окреме середовище RAPIDS:

```bash
conda create -n rapids-25.10 -c rapidsai -c conda-forge -c nvidia rapids=25.10 python=3.10 cuda-version=12.5
conda activate rapids-25.10
```

2) Встановіть залежності тюнінгу (безпечний варіант для RAPIDS env):

```bash
pip install -r requirements_rapids_tuning.txt
```

`requirements_rapids_tuning.txt` навмисно не містить `torch/torchvision`, щоб не ламати RAPIDS CUDA-залежності.

3) Налаштуйте Linux-шляхи у `config.yaml`:

- `input_dir: "/mnt/d/datasets_images/dataset"`
- `output_dir: "/mnt/d/dataset_filtered_by_presets"`

4) Увімкніть auto backend:

```yaml
acceleration:
  backend: "auto"
```

#### 3 команди перевірки GPU (RAPIDS + PyTorch)

```bash
python -c "import cupy as cp, cuml; print('cuML', cuml.__version__); print('CUDA devices', cp.cuda.runtime.getDeviceCount()); print('GPU', cp.cuda.runtime.getDeviceProperties(0)['name'])"
```

```bash
python -c "from cuml.decomposition import PCA; from cuml.manifold import UMAP; from cuml.cluster import HDBSCAN; import cupy as cp, numpy as np; X=cp.random.random((20000,64),dtype=cp.float32); Z=PCA(n_components=16).fit_transform(X); E=UMAP(n_components=3,n_neighbors=30,min_dist=0.0).fit_transform(Z); y=HDBSCAN(min_cluster_size=50).fit_predict(E); print('OK', int(np.sum(cp.asnumpy(y!=-1))))"
```

```bash
python -c "import torch; print('torch', torch.__version__); print('cuda', torch.cuda.is_available()); print('device', torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'none')"
```

#### Важливо про `pip install torch` у RAPIDS env

Не рекомендується ставити `torch/torchvision` через `pip` поверх RAPIDS-середовища, бо це може перезаписати CUDA-залежності (`cuda-bindings`, `cuda-python`) і зламати `cupy/cuml`.

Якщо так сталося:

- найнадійніше — створити нове чисте `conda` середовище RAPIDS заново;
- або тримати окреме env для feature extraction (PyTorch) і окреме env для RAPIDS-тюнінгу.

## Візуалізації

### interactive_scatter.html

Інтерактивний 3D scatter plot (Plotly). Кожна точка — зображення, колір — кластер. На бічній панелі при наведенні курсора показується мініатюра зображення та метадані.

Керування:
- **Обертання**: ЛКМ + тягнути
- **Зум**: колесо миші
- **Переміщення**: ПКМ + тягнути
- Кнопка «Скинути камеру» повертає вид за замовчуванням
- Кнопка «Авто-обертання» вмикає повільне обертання сцени

### cluster_grid.png

Статична сітка з вибіркою зображень кожного кластера. Дозволяє швидко оцінити якість кластеризації — чи дійсно кожен кластер містить один пресет.

### cluster_sizes.png

Стовпчикова діаграма кількості зображень у кожному кластері. Дозволяє побачити баланс і виявити аномально великі/малі кластери.

### preprocessing_comparison.png

Порівняння препроцесингу: оригінал → CLAHE(normal) → CLAHE(inverted). Показує, що саме «бачить» модель при dual-pass.

## Нічний тюнінг (`iterative_tuning.py`)

Окремий скрипт у корені проєкту для масового пошуку гіперпараметрів кластеризації з автоматичним purity-оцінюванням.

### Для чого потрібен

- Запускати багато ітерацій підряд без ручного втручання (на ніч).
- Автоматично зберігати метрики і відбирати найкращі конфіги.
- Працювати у двофазному режимі: швидкий пошук на частині даних + дооцінка на 100% датасету.

### Запуск

```bash
python iterative_tuning.py
```

Базовий конфіг береться з `config.yaml` (через `BASE_CONFIG_PATH` у скрипті).

### Режими пошуку

- `SEARCH_STRATEGY = "evolution"` — генетичний пошук (рекомендований для дорогих запусків).
- `SEARCH_STRATEGY = "grid"` — рівномірна вибірка з повного `SEARCH_SPACE`.

### Що тюниться

Скрипт читає простір параметрів із `SEARCH_SPACE` (ключі формату `section.param`), наприклад:

- `reduction.umap_components`
- `reduction.umap_n_neighbors`
- `clustering.min_cluster_size`
- `clustering.min_samples`
- `clustering.cluster_selection_epsilon`
- `clustering.cluster_selection_method`
- `purity.max_nn_cross_ratio` (якщо додасте в `SEARCH_SPACE`)

Додавати нові параметри можна напряму в `SEARCH_SPACE`; скрипт автоматично підставить їх у відповідну секцію конфіга.

### Двофазний режим

Керується флажками:

- `TWO_PHASE_ENABLED`
- `PHASE1_FRACTION`
- `PHASE1_BUDGET_RATIO`
- `PHASE2_TOP_K_SEEDS`

Логіка:

1. **Фаза 1**: оцінка на частці датасету (наприклад 50%).
2. **Фаза 2**: запускається на 100% даних, стартуючи з top-k кандидатів фази 1.

Це значно економить час і зменшує ризик витратити бюджет на слабкі області простору.

### Early stop (плато)

Керується флажками:

- `EARLY_STOP_ENABLED`
- `EARLY_STOP_PATIENCE_GENERATIONS`
- `EARLY_STOP_MIN_EVALUATIONS`

Якщо найкращий score не покращується кілька поколінь підряд, фаза зупиняється достроково.

### Куди пишуться результати і логи

- Детальний прогрес — у stdout консолі під час запуску (кожна ітерація друкує:
  - параметри,
  - `verdict`,
  - `max_centroid_cosine`,
  - `silhouette`,
  - `max_nn_cross_ratio`,
  - ETA).
- Артефакти кожної ітерації:
  - `D:/dataset_filtered_by_presets/_tuning/<iteration_name>/viz/purity_report_latest.json`
  - `D:/dataset_filtered_by_presets/_tuning/<iteration_name>/viz/centroid_cosine_matrix.npy`
- Загальний підсумок запуску:
  - `D:/dataset_filtered_by_presets/_tuning/tuning_summary_latest.json`
- Кеш індексу зображень для швидкого старту:
  - `./.cache/image_index_<hash_input_dir>.json`
  - при увімкненому `REUSE_IMAGE_INDEX=True` повторні запуски пропускають повний scan.

У консолі також явно видно активний backend:

- `Backend (reduction): RAPIDS (GPU)` або `CPU`
- `Backend (clustering): RAPIDS (GPU)` або `CPU`
- `Backend (purity): RAPIDS (GPU)` або `CPU`

### Наскільки інформативне логування

`tuning_summary_latest.json` містить:

- `best` — найкращий знайдений конфіг і його метрики;
- `top20` — топ-20 варіантів;
- `all_results` — усі прогони з параметрами, статусом і шляхом до purity-звіту.

Цього достатньо, щоб:

- відтворити будь-яку ітерацію;
- порівняти покоління/режими;
- зафіксувати фінальні параметри для `main.py`.

### Чи потрібні графіки

Для відбору найкращих гіперпараметрів **обов'язкові графіки не потрібні** — метрик у summary зазвичай достатньо.

Графіки доцільно будувати вже для:

- фінальних 3-10 конфігів (boxplot/lineplot по `max_centroid_cosine`, `silhouette`);
- аналізу динаміки поколінь у фазі 1/2;
- відладки аномалій (коли метрики суперечливі).

Тобто: спочатку числовий відбір, потім точкова візуальна валідація shortlist.

## Поради з налаштування

### Типовий сценарій: тепловізійні PTZ-камери

```yaml
model:
  name: "dinov2_vitb14"
  image_size: 518
  batch_size: 48        # для RTX 4090; менше для слабших GPU

preprocessing:
  clahe: true
  clahe_clip_limit: 3.0
  polarity_invariant: true
  l2_normalize: true
  trim_top: 0.03          # обрізка OSD (дата/час зверху)
  trim_bottom: 0.03       # обрізка OSD знизу

reduction:
  pca_components: 100
  umap_components: 5
  umap_n_neighbors: 30
  umap_min_dist: 0.0
  umap_metric: "cosine"

clustering:
  min_cluster_size: 200   # підлаштувати під розмір датасету
  min_samples: 2
  cluster_selection_epsilon: 0.5
  cluster_selection_method: "leaf"
  noise_handling: "nearest"
```

### Типовий сценарій: звичайні RGB-камери

```yaml
model:
  name: "dinov2_vitb14"
  image_size: 518

preprocessing:
  clahe: false
  polarity_invariant: false
  l2_normalize: true

reduction:
  pca_components: 100
  umap_components: 5
  umap_n_neighbors: 30
  umap_min_dist: 0.0
  umap_metric: "cosine"

clustering:
  min_cluster_size: 100
  min_samples: 5
  cluster_selection_epsilon: 0.3
  cluster_selection_method: "eom"
  noise_handling: "nearest"
```

### Якщо HDBSCAN знаходить забагато кластерів

1. Збільшити `cluster_selection_epsilon` (0.3 → 0.5 → 0.8)
2. Збільшити `min_cluster_size`
3. Спробувати `cluster_selection_method: "eom"`
4. Зменшити `umap_components` (5 → 3)

### Якщо HDBSCAN знаходить замало кластерів

1. Зменшити `min_cluster_size` (200 → 100 → 50)
2. Зменшити `cluster_selection_epsilon` (0.5 → 0.0)
3. Збільшити `min_samples` (2 → 5 → 10)
4. Збільшити `umap_components` (5 → 8)
5. Зменшити `umap_n_neighbors` (30 → 15)

### Якщо один кластер містить кілька пресетів

Це означає, що модель не бачить різниці між ними. Можливі дії:
1. Збільшити `image_size` (224 → 518) для кращих ознак
2. Перейти на більшу модель (`vits14` → `vitb14`)
3. Зменшити `cluster_selection_epsilon`
4. Зменшити `min_cluster_size`
5. Збільшити `umap_n_neighbors` для кращої глобальної структури

### Швидкість: чого очікувати

Для датасету ~10 000 зображень з RTX 4090:
- Витягування ознак (ViT-B@518, dual-pass): ~3–5 хв
- PCA + UMAP: ~30 сек
- HDBSCAN: ~3 сек
- Візуалізації: ~1–2 хв
- Повторний запуск (з кешу): ~2 хв (без inference)
